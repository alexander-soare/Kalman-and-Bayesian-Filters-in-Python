{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reminder of what \"covariance\" is.\n",
    "\n",
    "$$\n",
    "\\sigma_{xy} = \\sigma_{yx} = \\mathbb{E}\\bigl[(X-\\mu_x)(Y-\\mu_y) \\bigr]\n",
    "$$\n",
    "\n",
    "Here is the multivariate normal distribution in $n$ dimensions.\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x},\\, \\mu,\\,\\Sigma) = \\frac{1}{\\sqrt{(2\\pi)^n|\\Sigma|}}\\, \\exp  \\Big [{ -\\frac{1}{2}(\\mathbf{x}-\\mu)^\\mathsf{T}\\Sigma^{-1}(\\mathbf{x}-\\mu) \\Big ]}\n",
    "$$\n",
    "\n",
    "where $\\Sigma$ is the covariance matrix and $|\\Sigma|$ is the determinant of $\\Sigma$ aka the \"generalized variance\". Determinant kind of makes sense because remember from 3b1b that it kind of tells us how a matrix scales the area of a unit square, and we are using this term to normalize the area under the curve.\n",
    "\n",
    "Pearson's correlation coefficient is:\n",
    "\n",
    "$$\n",
    "\\rho_{xy} = \\frac{\\sigma_{xy}}{\\sigma_x \\sigma_y}\n",
    "$$\n",
    "\n",
    "Covariance has units and pearson's correlation coefficient is unitless. Covariance can have any value, but Pearson's correlation coefficient lies in [-1, 1]. Side note: when evaluating the relationship between variables covariance can sometimes be misleading. Imagine comparing the covariance of some $x$ with itself. That's just the variance. If you consider $y=2x$ the variance is 4x bigger but the relationship looks the same. Even if you add noise to $y$ the covariance will still be greater than when we did $x$, so that's a bit misleading. Correlation doesn't care about scale. The sign just tells us the slope of the line of best fit, and the closer it is to 1 (or -1) the better the fit.\n",
    "\n",
    "Here are the equations for the product of multivariate gaussian pdfs\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu &= \\Sigma_2(\\Sigma_1 + \\Sigma_2)^{-1}\\mu_1 + \\Sigma_1(\\Sigma_1 + \\Sigma_2)^{-1}\\mu_2 \\\\\n",
    "\\Sigma &= \\Sigma_1(\\Sigma_1+\\Sigma_2)^{-1}\\Sigma_2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Recall that for the univariate case they were:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu &=\\frac{\\sigma_2^2\\mu_1 + \\sigma_1^2\\mu_2}{\\sigma_1^2+\\sigma_2^2}\\\\\n",
    "\\sigma^2 &=\\frac{\\sigma_1^2\\sigma_2^2}{\\sigma_1^2+\\sigma_2^2} \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "so these are basically the same although you might need to do some index tracking for the multivariate case.\n",
    "\n",
    "A multivariate Kalman filter can perform better than a univariate one because we can exploit covariance when multiplying likelihood with prior.\n",
    "\n",
    "![](.images/2022-06-17-10-58-35.png)\n",
    "\n",
    "Three types of variable:\n",
    "- Observed variable - Like the radar sensor for the plane being able to get its position.\n",
    "- Hidden variable - Like the incorporation to two radar measurement to infer the velocity.\n",
    "- Unobserved variable - Like the color of the plane which simply has no bearing on the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6050d9bfd2fcb1ca8ac8d9d8f2b9c15d7b67eb6846d4d3f06614601d6453a836"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
